% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/connecticutRiverModel.R
\name{connecticutRiverModel}
\alias{connecticutRiverModel}
\title{Connecticut River Model}
\usage{
connecticutRiverModel(nRuns = 1, nYears = 40, timing = 1,
  upstream = list(holyoke = 1, cabot = 1, spillway = 1, gatehouse = 1, vernon
  = 1), downstream = list(holyoke = 1, cabot = 1, gatehouse = 1, vernon = 1),
  northfield = list(turnersA = 1, turnersJ = 1, vernonA = 1, vernonJ = 1),
  pSpillway = 0.5, inRiverF = 0, commercialF = 0, bycatchF = 0,
  indirect = 1, latent = 1, watershed = TRUE)
}
\arguments{
\item{nRuns}{The number of times that the
model will be run.}

\item{nYears}{The number of years for which
each run will last. The default is 40 years
to match current license lengths in the 
Connecticut River.}

\item{timing}{The amount of time required for
upstream passage by individual fish (in days),
where the default (1) indicates a 24-h dam
passage performance standard.}

\item{upstream}{A named list of upstream dam
passage efficiencies at each dam in the
Connecticut River.

Users may specify a single value of upstream
passage at each dam, or a vector of upstream
passage efficiencies at each dam. Note that
passage efficiences passed as vectors are
randomly sampled during each model run
(not each year). Therefore, multiple model runs
are necessary if more than one passage efficiency
is supplied for any dam.}

\item{downstream}{A named list of downstream
dam passage efficiencies at each dam in the
Connecticut River.

Users may specify a single value of downstream
passage at each dam, or a vector of downstream
passage efficiencies at each dam. Note that
passage efficiences passed as vectors are
randomly sampled during each model run
(not each year). Therefore, multiple model runs
are necessary if more than one passage efficiency
is supplied for any dam.}

\item{northfield}{Annual take for juveniles and
adults from PU IV and PU V at the Northfield
Mountain pumped power storage facility.}

\item{pSpillway}{Probability of using the spillway
route for passage through the Turner's Falls
hydropower complex.}

\item{inRiverF}{Annual, recreational harvest of
American shad. Parameterized as an annual rate [0, 1].}

\item{commercialF}{Commercial fishery mortality
for American shad in marine environment incurred
through targeted fisheries. Parameterized as an
annual rate [0, 1].}

\item{bycatchF}{Marine bycatch mortality of
American shad in non-target fisheries.
Parameterized as an annual rate [0, 1].}

\item{indirect}{Indirect mortality incurred during
freshwater migration as a result of dam-related
impacts (e.g., injury, predation, etc.).}

\item{latent}{Latent mortality incurred during estuary
passage as a result of dam-related impacts (e.g., injury,
delay, etc.).}

\item{watershed}{A logical indicating whether or not
to use the same dam passage efficiencies at all dams
for upstream and downstream. If watershed = TRUE, then
the first element in lists `upstream` and `downstream`
are recycled for all subsequent dams.}
}
\value{
Returns a dataframe of user-defined
inputs and available model outputs for each use that
contains \code{nRuns} x \code{nYears} number of rows.

If run in parallel, returns a list
of dataframes.

The folowing named columns are returned:
\itemize{
    \item \code{year} Year of simulation

    \item \code{time} Passage timing input by user

    \item \code{HolyokeUp...BellowsUp} User-specified upstream passage efficiencies

    \item \code{HolyokeD...BellowsD}  User-specified downstream passage efficiencies

    \item \code{pRepeat_Age1...Age8} Age-specific probability of repeat spawning

    \item \code{populationSize} Total number of adult spawners returning to the river

    \item \code{N_I...N_V} Production unit-specific population size after in-river fishery mortality
}
}
\description{
Runs American shad dam passage performance
standard model for Connecticut River, USA
}
\section{Warning about serial execution and memory limits}{

Current implementation is based on work
in press, and is thus subject to modification
without notice.

Currently, internal functions rely on `\code{list2env}` to return
lists to a temporary environment created in the
\code{connecticutRiverModel} function. Consequently, lists
that are exported must be limited in size. Therefore,
users currently need to limit the number of runs per
call (\code{nRuns} argument) to less than 10 or R will
hit memory limits quickly. In reality, serial
execution is prohibitively slow unless implemented
using manual parallel processing (e.g., bash scripting).

In order to achieve a desired number of runs for a given
set of inputs, the recommended approach is to use
parallel execution as demonstrated using snowfall in the
example at the bottom of this page.
}

\examples{
# Parallel execution on a local cluster
# -------------------------------------------------------------------------
\dontrun{
  
# R snowfall example

# Load R packages
  library(snowfall)
  library(rlecuyer)
  library(shadia)

# 1. Initialization of snowfall.
# -----  
# Initialize parallel mode using sockets and
# command-line args
sfInit(parallel=TRUE, cpus=3, type="SOCK")

# Display information about nodes and processes
# used by this job. This is entirely optional,
# to demonstrate snowfall methods sfClusterCall()
# and sfCpus().

# Describe the nodes and cpus:
cat(paste0('CPU count: ', sfCpus()), fill=TRUE)

# Count off each process with anonymous function
cat('CPU ids: ', unlist(sfClusterCall(function() Sys.getpid())), fill=TRUE)

# 2. Load data. 
# -----
data('fish')
data('arr.B')
data('arr.R')
data('b.parms')
data('r.parms')
data('tempD')
data('tempData_connecticut')

# 3. Define wrapper function, which can be called in parallel.
#
#   Runs connecticutRiverModel() on each worker
#
#   Here, workerId just contains the identity of the cpu that perfomed
#   the work. We do this only to prove we have used all the specified cpus!
#   Ideally, we will minimize the data sent to (and returned from) the workers.
#
#   Note that constructing and returning a list enables the function to
#   return more than one output.
# -----
wrapper <- function(idx) {

# Get cpu ids  
  workerId <- paste(Sys.info()[['nodename']],
                    Sys.getpid(),
                    sep='-'
                    )

# Run the model
res1 <- connecticutRiverModel(nYears = 40,
                            upstream = list(
                              holyoke = seq(0, 1, 0.10),
                              cabot = seq(0, 1, 0.10),
                              spillway = seq(0, 1, 0.10),
                              gatehouse = seq(0, 1, 0.10),
                              vernon = seq(0, 1, 0.10)
                            ),
                            downstream = list(
                              holyoke = seq(0, 1, 0.10),
                              cabot = seq(0, 1, 0.10),
                              gatehouse = seq(0, 1, 0.10),
                              vernon = seq(0, 1, 0.10)
                            ),
                            pSpillway = 1
        )

# Define the output lists
    retlist <- list(
      worker=workerId,
      res=res1)       
    return(retlist)
}

# 4. Export needed data to workers 
#    load required packages on workers.
# -----
sfLibrary(shadia)

# 5. Start network random number generator 
#    (as "sample" uses random numbers).
# -----
sfClusterSetupRNG()

# 6. Distribute calculation to workers
# -----
niterations <- 10
start <- Sys.time()

# The magic is in snowfall's sfLapply() function,
# which sends wrapper() out to the workers:
result <- sfLapply(1:niterations, wrapper) 

Sys.time()-start

# 7. Stop snowfall
# -----
sfStop()

# 8. Examine the results returned from the cluster:
# -----

# 'result' is a list of lists. Save this:
save(result, file = "snowfall-result.rda")

# Extract results dataframes by string and rbind them
res <- lapply(result, function(x) x[[c('res')]])
resdf <- do.call(rbind, res)

plot(resdf$year, resdf$populationSize)

}
}
