% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PenobscotRiverModel.R
\name{penobscotRiverModel}
\alias{penobscotRiverModel}
\title{Penobscot River Model}
\usage{
penobscotRiverModel(
  nRuns = 1,
  species = "shad",
  nYears = 50,
  timing = list(1, 1, 1, 1, 1, 1, 1),
  upstream = list(milford = 1, howland = 1, westEnfield = 1, brownsMill = 1, moosehead
    = 1, guilford = 1, weldon = 1),
  downstream = list(stillwater = 1, orono = 1, milford = 1, howland = 1, westEnfield =
    1, brownsMill = 1, moosehead = 1, guilford = 1, weldon = 1),
  pinHarvest = 0,
  inRiverF = 0,
  commercialF = 0,
  bycatchF = 0,
  indirect = 1,
  latent = 1,
  watershed = TRUE,
  climate = "current",
  k_method = "cumulative"
)
}
\arguments{
\item{nRuns}{The number of times that the
model will be run.}

\item{species}{Species for which the model will be
run. Current options include \code{'shad'} and
\code{'blueback'}.}

\item{nYears}{The number of years for which
each run will last. The default is 50 years
to match hydropower license duration in the
Penobscot River.}

\item{timing}{The amount of time required for
upstream passage by individual fish (in days), 
where the default (1) indicates a 24-h dam
passage performance standard.}

\item{upstream}{A named list of upstream dam
passage efficiencies at each dam in the 
Penobscot River. Stillwater and Orono dams are
not included in the list of values because all
fish reaching Orono Dam are "trucked" upstream.

Users may specify a single value of upstream
passage at each dam, or a vector of upstream
passage efficiencies at each dam. Note that
passage efficiences passed as vectors are 
randomly sampled during each model run 
(not each year). Therefore, multiple model runs
are necessary if more than one passage efficiency
is supplied for any dam.}

\item{downstream}{A named list of downstream
dam passage efficiencies at each dam in the 
Penobscot River (including Orono and Stillwater
dams). 

Users may specify a single value of downstream
passage at each dam, or a vector of downstream
passage efficiencies at each dam. Note that
passage efficiences passed as vectors are 
randomly sampled during each model run 
(not each year). Therefore, multiple model runs
are necessary if more than one passage efficiency
is supplied for any dam.}

\item{pinHarvest}{In-river, sustenance harvest
by Penobscot Indian Nation (PIN) upstream of Weldon 
Dam. Parameterized as an annual rate [0, 1].}

\item{inRiverF}{Annual, recreational harvest of 
American shad downstream of Weldon Dam. 
Parameterized as an annual rate [0, 1].}

\item{commercialF}{Commercial fishery mortality
for American shad in marine environment incurred 
through targeted fisheries. Parameterized as an 
annual rate [0, 1].}

\item{bycatchF}{Marine bycatch mortality of
American shad in non-target fisheries. 
Parameterized as an annual rate [0, 1].}

\item{indirect}{Indirect mortality incurred during
freshwater migration as a result of dam-related
impacts (e.g., injury, predation, etc.).}

\item{latent}{Latent mortality incurred during estuary
passage as a result of dam-related impacts (e.g., injury,
delay, etc.).}

\item{watershed}{A logical indicating whether or not
to use the same dam passage efficiencies at all dams
for upstream and downstream. If watershed = TRUE, then
the first element in lists `upstream` and `downstream`
are recycled for all subsequent dams.}

\item{climate}{Character string indicating scenario to
be used for temperature projections. Available options
include '\code{current}', '\code{rcp45}', and '\code{rcp85}'.
This argument is only implemented in \code{connecticutRiverModel}.
If \code{species == blueback} then `climate` must be set to 
`current`.}

\item{k_method}{Method used to impose carrying capacity. The 
default, 'cumulative' assumes that carrying capacity is based on 
all available habitat across all occupied production units. The 
alternative, 'discrete' assumes that carrying capacity is applied
within discrete production units based on the numbers, and was the
method used in Stich et al. (2019).}
}
\value{
Returns a list of two named dataframes.
The first dataframe (\code{res}) contains user-defined
inputs and available model outputs.

If run in parallel, returns a list of lists
of dataframes.

The folowing named columns are returned in \code{res}:
\itemize{
    \item \code{year} Year of simulation
    \item \code{time_milford...time_guilford} Passage timing input by user
    \item \code{milford_up...guilford_up} User-specified upstream passage efficiencies
    \item \code{stillwater_down...weldon_down}  User-specified downstream passage efficiencies
    \item \code{pRepeat_Age1...Age9} Age-specific probability of repeat spawning  
    \item \code{populationSize} Total number of adult spawners returning to the river
    \item \code{N_pu1A2A...N_pu4B} Production unit-specific population size after in-river fishery mortality
}

The following named columns are returned in \code{sens}:
\itemize{
    \item \code{pStillUP} Probability of fish using the Stillwater Branch for upstream migration
    \item \code{pStillD} Probability of fish using the Stillwater Branch for downstream migration
    \item \code{pPiscUP} Probability of fish using the Piscataquis River during upstream migration
    \item \code{S.downstream} Downstream survival per kilometer
    \item \code{S.marine} Marine survival
    \item \code{popStart} Starting population size
    \item \code{p.female} Probability of being female
    \item \code{S.prespawnM} Prespawn survival rate for males
    \item \code{S.postspawnM} Postspawn survival rate for males
    \item \code{S.prespawnF} Postspawn survival rate for males
    \item \code{S.postspawnF} Postspawn survival rate for males
    \item \code{S.juvenile} Hatch to out-migrant survival rate
    \item \code{t.stoch} Temperature stochasticity parameter
    \item \code{b.Arr} Mean arrival date for males
    \item \code{r.Arr} Mean arrival date for females
    \item \code{ATUspawn1} Accumulated thermal units at initiation of spawn
    \item \code{ATUspawn2} Accumulated thermal units at termination of spawn
    \item \code{Dspawn1} Initial spawning date
    \item \code{Dspawn2} Terminal spawning date
    \item \code{linF} L-infinity parameter from the von Bertalanffy growth function for females
    \item \code{kF} K parameter from the von Bertalanffy growth function for females
    \item \code{t0F} t0 parameter from the von Bertalanffy growth function for females
    \item \code{linM} L-infinity parameter from the von Bertalanffy growth function for males
    \item \code{kM} K parameter from the von Bertalanffy growth function for males
    \item \code{t0M} t0 parameter from the von Bertalanffy growth function for males
    \item \code{b.length} Mean length of males
    \item \code{r.length} Mean length of females
    \item \code{spawnInt} Mean spawning interval
    \item \code{batchSize} Mean batch size
    \item \code{resTime} Mean residence time
    \item \code{s.Optim} Mean optimal ground speed
    \item \code{d.Max} Mean maximum daily movement rate
    \item \code{tortuosity} Path tortuosity parameter
    \item \code{motivation} Seasonal change in fish "motivation" for upstream movement
    \item \code{daily.move} Mean realized daily movement rate
    \item \code{habStoch} Habitat stochasticity
}
}
\description{
Runs American shad dam passage performance
standard model for Penobscot River, Maine,
USA
}
\section{Schematic of production units}{

Production units delineated by dams in the watershed. 
Circles are log proportional to carrying capacity in 
each unit. Black dots indicate no suitable habitat 
in a unit. 
 
\if{html}{\figure{penobscot.png}{Penobscot River}}
\if{latex}{\figure{penobscot.png}{options: width=0.5in}}
}

\section{Warning about serial execution and memory limits}{


Currently, internal functions rely on \code{list2env} to return
lists to a temporary environment created in the 
\code{penobscotRiverModel} function. Consequently, lists 
that are exported must be limited in size. Therefore, 
users currently need to limit the number of runs per 
call (\code{nRuns} argument) to less than 10 or R will 
hit memory limits quickly. In reality, serial 
execution is prohibitively slow unless implemented 
using manual parallel processing (e.g., bash scripting).

In order to achieve a desired number of runs for a given
set of inputs, the recommended approach is to use 
parallel execution as demonstrated using snowfall in the
example below.
}

\examples{
# Parallel execution on a local cluster
\dontrun{
  
# R snowfall example

# Load R packages
  library(snowfall)
  library(rlecuyer)
  library(shadia)
  library(plyr)

# 1. Initialization of snowfall.
# Initialize parallel mode using sockets and
# command-line args
sfInit(parallel=TRUE, cpus=3, type="SOCK")

# Display information about nodes and processes
# used by this job. This is entirely optional,
# to demonstrate snowfall methods sfClusterCall()
# and sfCpus().

# Describe the nodes and cpus:
cat(paste0('CPU count: ', sfCpus()), fill=TRUE)

# Count off each process with anonymous function
cat('CPU ids: ', unlist(sfClusterCall(function() Sys.getpid())), fill=TRUE)

# 2. Load data. 
# -----
data('fish')
data('arr.B')
data('arr.R')
data('b.parms')
data('r.parms')
data('tempD')
data('tempData')

# 3. Define wrapper function, which can be called in parallel.
#
#   Runs penobscotRiverModel on each worker
#
#   Here, workerId just contains the identity of the cpu that perfomed
#   the work. We do this only to prove we have used all the specified cpus!
#   Ideally, we will minimize the data sent to (and returned from) the workers.
#
#   Note that constructing and returning a list enables the function to
#   return more than one output.

wrapper <- function(idx) {

  # Get cpu ids  
    workerId <- paste(Sys.info()[['nodename']],
                      Sys.getpid(),
                      sep='-'
                      )
  
  # Run the model
  res1 <- penobscotRiverModel(
          nRuns = 1,
          nYears = 50,
          timing = list(1,1,1,1,1,1,1),
          upstream = list(
            milford = 1,
            howland = 1,
            westEnfield = 1,
            brownsMill = 1,
            moosehead = 1,
            guilford = 1,
            weldon = 1
          ),
          downstream = list(
            stillwater = 1,
            orono = 1,
            milford = 1,
            howland = 1,
            westEnfield = 1,
            brownsMill = 1,
            moosehead = 1,
            guilford = 1,
            weldon = 1
          ),
          pinHarvest = 0,
          inRiverF = 0,
          commercialF = 0,
          bycatchF = 0,
          indirect = 1,
          latent = 1,
          watershed = TRUE
  )
  
  # Define the output lists
      retlist <- list(
        worker=workerId,
        sim=res1)       
      return(retlist)
}

# 4. Export needed data to workers 
#    load required packages on workers.
  sfLibrary(shadia)

# 5. Start network random number generator 
#    (as "sample" uses random numbers).
#    sfClusterSetupRNG()

# 6. Distribute calculation to workers
  niterations <- 30
  start <- Sys.time()

  # Use sfLapply() function to send wrapper() to the workers:
    result <- sfLapply(1:niterations, wrapper) 
    
# 7. Stop snowfall
  Sys.time()-start  
  sfStop()

# 8. Examine the results returned from the cluster:

# 'result' is a list of lists. Save this:
# save(result, file = "snowfall-result.rda")

# Extract results list from output list
  out <- lapply(result, function(x) x[[c('sim')]])

# Extract user inputs and population metrics
  res <- lapply(out, function(x) x[[c('res')]])
  resdf <- do.call(rbind, res)

# Extract sensitivity variables
  sens <- lapply(out, function(x) x[[c('sens')]])
  sensdf <- do.call(rbind, sens)

# Have a look at result  
  plotter <- ddply(resdf, 'year', summarize,
                   mu=mean(populationSize))
  plot(plotter$year, plotter$mu, type = 'l')

}
}
